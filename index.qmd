---
title: "Regression & Interpretability Challenge"
subtitle: "Don't Trust Linear Models - The Perils of Non-Linearity"
format:
  html: default
execute:
  echo: false
  eval: true
---

# Answers

```{python}
#| label: setup
import pandas as pd
import numpy as np
from scipy import stats
import seaborn as sns
import matplotlib.pyplot as plt

sns.set_theme(style="whitegrid")
plt.rcParams["figure.figsize"] = (7, 4)

observDF = pd.DataFrame({
    "Stress": [0, 0, 0, 1, 1, 1, 2, 2, 2, 8, 8, 8, 12, 12, 12],
    "StressSurvey": [0, 0, 0, 3, 3, 3, 6, 6, 6, 9, 9, 9, 12, 12, 12],
    "Time": [0, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2.1, 2.2, 2.2, 2.2],
    "Anxiety": [0, 0.1, 0.1, 1.1, 1.1, 1.1, 2.2, 2.2, 2.2, 8.2, 8.2, 8.21, 12.22, 12.22, 12.22],
})

def run_ols(df, y_col, x_cols):
    y = df[y_col].to_numpy()
    X_raw = df[x_cols].to_numpy()
    X = np.column_stack([np.ones(len(df)), X_raw])
    XtX_inv = np.linalg.inv(X.T @ X)
    beta = XtX_inv @ X.T @ y
    y_hat = X @ beta
    resid = y - y_hat
    n = len(y)
    p = X.shape[1]
    dof = n - p
    sse = resid @ resid
    sigma2 = sse / dof if dof > 0 else 0.0
    se = np.sqrt(np.diag(sigma2 * XtX_inv))
    with np.errstate(divide="ignore", invalid="ignore"):
        t_stats = beta / se
    p_values = 2 * (1 - stats.t.cdf(np.abs(t_stats), dof)) if dof > 0 else np.zeros_like(beta)
    ss_total = np.sum((y - y.mean()) ** 2)
    r_squared = 1 - sse / ss_total if ss_total > 0 else 1.0
    index = ["Intercept"] + x_cols
    return {
        "params": pd.Series(beta, index=index),
        "se": pd.Series(se, index=index),
        "pvals": pd.Series(p_values, index=index),
        "rsq": r_squared,
        "dof": dof,
    }

results = {
    "stresssurvey": run_ols(observDF, "Anxiety", ["StressSurvey"]),
    "time": run_ols(observDF, "Anxiety", ["Time"]),
    "surv_time": run_ols(observDF, "Anxiety", ["StressSurvey", "Time"]),
    "stress_time": run_ols(observDF, "Anxiety", ["Stress", "Time"]),
}

subset_mask = observDF["StressSurvey"] <= 6
subsetDF = observDF[subset_mask].copy()
results["subset"] = run_ols(subsetDF, "Anxiety", ["StressSurvey", "Time"])

def tidy(result):
    return pd.concat(
        [
            result["params"].rename("Estimate"),
            result["se"].rename("Std. Err."),
            result["pvals"].rename("p-value"),
        ],
        axis=1,
    )

tables = {name: tidy(res) for name, res in results.items()}

tables["surv_time"]["True"] = pd.Series({"Intercept": 0.0, "StressSurvey": np.nan, "Time": 0.1})
tables["stress_time"]["True"] = pd.Series({"Intercept": 0.0, "Stress": 1.0, "Time": 0.1})
tables["subset"]["True"] = pd.Series({"Intercept": 0.0, "StressSurvey": 1 / 3, "Time": 0.1})

summary_df = pd.DataFrame({
    "Model": ["Anxiety ~ StressSurvey + Time", "Anxiety ~ Stress + Time"],
    "R-squared": [results["surv_time"]["rsq"], results["stress_time"]["rsq"]],
    "Stress/Survey coef": [results["surv_time"]["params"]["StressSurvey"], results["stress_time"]["params"]["Stress"]],
    "Stress/Survey p-value": [results["surv_time"]["pvals"]["StressSurvey"], results["stress_time"]["pvals"]["Stress"]],
    "Time coef": [results["surv_time"]["params"]["Time"], results["stress_time"]["params"]["Time"]],
    "Time p-value": [results["surv_time"]["pvals"]["Time"], results["stress_time"]["pvals"]["Time"]],
})
```

## Question 1 — What happens when I regress Anxiety on StressSurvey alone?

The proxy-only regression gives an intercept of -1.52 and a slope of 1.05, both flagged as significant. The true equation never mentioned StressSurvey, so that slope is the model bending the curve to mimic stress. The negative intercept is the giveaway that the straight line is forcing its way through a non-linear shape.

```{python}
tables["stresssurvey"].round(4)
```

## Question 2 — Does the StressSurvey scatter plot look linear?

Not really. The regression line cuts across a bend: low-stress points sit under the line while the high-stress clump sits way above it. The fit looks fine numerically, but the shape screams "use the real stress measure."

```{python}
#| label: fig-stresssurvey
fig, ax = plt.subplots()
sns.regplot(data=observDF, x="StressSurvey", y="Anxiety", ax=ax, scatter_kws={"s": 60}, line_kws={"color": "black"})
ax.set_title("Anxiety vs. StressSurvey")
ax.set_xlabel("Stress Survey Response")
ax.set_ylabel("Anxiety")
plt.tight_layout()
plt.show()
```

## Question 3 — What if I regress Anxiety on Time alone?

Time by itself looks ultra-important: the slope jumps to 5.34 with a loud p-value, even though the true effect is only 0.1. Leaving out stress pushes the regression to pin everything on screen time.

```{python}
tables["time"].round(4)
```

## Question 4 — Does the Time scatter plot back up that story?

Not really. Anxiety is flat for the first two hours of social media and then shoots up for the stressed students who also happen to be online longer. The best-fit line tilts up anyway, so it tells a causal story that simply is not there.

```{python}
#| label: fig-time
fig, ax = plt.subplots()
sns.regplot(data=observDF, x="Time", y="Anxiety", ax=ax, scatter_kws={"s": 60}, line_kws={"color": "black"})
ax.set_title("Anxiety vs. Time on Social Media")
ax.set_xlabel("Minutes on Social Media (24h)")
ax.set_ylabel("Anxiety")
plt.tight_layout()
plt.show()
```

## Question 5 — What happens when I add StressSurvey and Time together?

The model fires off a StressSurvey coefficient of 1.43 and flips the Time coefficient to -2.78, both with tiny p-values. We now have "more time online lowers anxiety" as a statistically significant claim, even though the true data-generating process says the opposite.

```{python}
tables["surv_time"].round(4)
```

## Question 6 — What if I use the actual Stress measure with Time?

Using the real stress variable recovers the known equation almost perfectly: intercept 0, stress coefficient 1, and time coefficient 0.1. With the right inputs the regression finally behaves.

```{python}
tables["stress_time"].round(4)
```

## Question 7 — How do the two multiple regressions compare?

Both models boast high $R^2$, and both tout significant coefficients on every predictor. Yet only the model with true stress lands on the correct signs and magnitudes. The survey-based model looks great on paper while utterly misrepresenting the time effect.

```{python}
summary_df.round(4)
```

## Question 8 — How could these results get spun?

The survey-based model would yield a headline like "More Instagram Time Calms Stressed Students, Study Finds." The model with true stress screams "Stress and Screen Time Combine to Spike Anxiety." A cautious parent will latch onto the second story; platform execs would wave around the first one as proof their apps are harmless.

## Question 9 — Can a smarter slice of the data fix the proxy problem?

I limited the sample to `StressSurvey ≤ 6`, where the survey scale tracks blood-test stress in neat 3-point steps. In that regime the regression lands on a StressSurvey slope of 0.33 (one-third of the true stress effect) and the correct 0.1 for time. The subset keeps significance while staying aligned with the real equation.

```{python}
tables["subset"].round(4)
```

